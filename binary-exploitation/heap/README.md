# 堆

## 堆基础

堆基本上是程序在请求数据时能够存储数据的地方，通过调用诸如**`malloc`**、`calloc`等函数。此外，当不再需要这些内存时，可以通过调用函数**`free`**来释放。

如图所示，堆就在二进制文件加载到内存后面（查看`[heap]`部分）：

<figure><img src="../../.gitbook/assets/image (1241).png" alt=""><figcaption></figcaption></figure>

### 基本块分配

当请求将一些数据存储在堆中时，堆的一些空间将被分配给它。这个空间将属于一个bin，并且只有请求的数据 + bin头部的空间 + 最小的bin大小偏移量将被保留给这个块。目标是尽可能保留最少的内存，而不会使查找每个块的位置变得复杂。为此，使用元数据块信息来知道每个已使用/空闲块的位置。

根据使用的bin，有不同的方式来保留空间，但一般的方法是：

* 程序首先请求一定量的内存。
* 如果在块列表中有足够大的可用块来满足请求，它将被使用。
* 这甚至可能意味着可用块的一部分将用于此请求，其余部分将被添加到块列表中。
* 如果列表中没有可用块，但已分配的堆内存中仍有空间，堆管理器将创建一个新块。
* 如果没有足够的堆空间来分配新块，堆管理器会要求内核扩展分配给堆的内存，然后使用这些内存来生成新块。
* 如果一切失败，`malloc`返回null。

请注意，如果请求的**内存超过阈值**，将使用**`mmap`**来映射请求的内存。

### 竞技场

在**多线程**应用程序中，堆管理器必须防止可能导致崩溃的**竞争条件**。最初，这是通过使用**全局互斥锁**来实现的，以确保一次只有一个线程可以访问堆，但这会导致由于互斥锁引起的性能问题。

为了解决这个问题，ptmalloc2堆分配器引入了“竞技场”，其中**每个竞技场**充当一个**独立的堆**，具有其**自己的**数据**结构**和**互斥锁**，允许多个线程执行堆操作而不会相互干扰，只要它们使用不同的竞技场。

默认的“主”竞技场处理单线程应用程序的堆操作。当**添加新线程**时，堆管理器为它们分配**次要竞技场**以减少争用。它首先尝试将每个新线程附加到未使用的竞技场，如有必要，创建新的竞技场，32位系统的限制为CPU核心的2倍，64位系统的限制为8倍。一旦达到限制，**线程必须共享竞技场**，可能导致争用。

与主竞技场不同，主竞技场使用`brk`系统调用扩展，次要竞技场使用`mmap`和`mprotect`创建“子堆”来模拟堆行为，允许灵活管理多线程操作的内存。

### 子堆

子堆用作多线程应用程序中次要竞技场的内存储备，允许它们独立增长和管理自己的堆区域，与主堆不同，子堆的运作方式如下：

1. **初始堆与子堆**：
* 初始堆位于程序二进制文件之后的内存中，并使用`sbrk`系统调用扩展。
* 次要竞技场使用的子堆是通过`mmap`创建的，这是一个映射指定内存区域的系统调用。
2. **使用`mmap`进行内存保留**：
* 当堆管理器创建子堆时，它通过`mmap`保留了一个大块内存。此保留不会立即分配内存；它只是指定其他系统进程或分配不应使用的区域。
* 默认情况下，32位进程的子堆保留大小为1 MB，64位进程为64 MB。
3. **使用`mprotect`逐步扩展**：
* 最初将保留的内存区域标记为`PROT_NONE`，表示内核不需要为此空间分配物理内存。
* 为了“增长”子堆，堆管理器使用`mprotect`将页面权限从`PROT_NONE`更改为`PROT_READ | PROT_WRITE`，促使内核为先前保留的地址分配物理内存。这一步骤逐步允许子堆根据需要扩展。
* 一旦整个子堆耗尽，堆管理器将创建一个新的子堆以继续分配。

### 元数据

如前所述，这些块也有一些元数据，在这个图像中很好地表示出来：

<figure><img src="../../.gitbook/assets/image (1242).png" alt=""><figcaption><p><a href="https://azeria-labs.com/wp-content/uploads/2019/03/chunk-allocated-CS.png">https://azeria-labs.com/wp-content/uploads/2019/03/chunk-allocated-CS.png</a></p></figcaption></figure>

元数据通常为0x08B，指示当前块大小，使用最后3位来指示：

* `A`：如果为1，则来自子堆，如果为0，则在主竞技场中
* `M`：如果为1，则此块是使用`mmap`分配的空间，而不是堆的一部分
* `P`：如果为1，则前一个块正在使用中

然后是用户数据的空间，最后是0x08B，用于指示块可用时的前一个块大小（或在分配时存储用户数据）。

此外，当可用时，用户数据还用于包含一些数据：

* 指向下一个块的指针
* 指向上一个块的指针
* 列表中下一个块的大小
* 列表中上一个块的大小

<figure><img src="../../.gitbook/assets/image (1243).png" alt=""><figcaption><p><a href="https://azeria-labs.com/wp-content/uploads/2019/03/chunk-allocated-CS.png">https://azeria-labs.com/wp-content/uploads/2019/03/chunk-allocated-CS.png</a></p></figcaption></figure>

请注意，以这种方式链接列表可以避免需要有一个包含每个单个块的数组。

## 释放保护

为了防止意外或有意的滥用`free`函数，在执行其操作之前会执行一些检查：

* 它检查地址是否[对齐](https://sourceware.org/git/gitweb.cgi?p=glibc.git;a=blob;f=malloc/malloc.c;h=6e766d11bc85b6480fa5c9f2a76559f8acf9deb5;hb=HEAD#l4182)在8字节或64位边界上对齐（`(address % 16) == 0`），因为_malloc_确保所有分配都是对齐的。
* 它检查块的大小字段是否不可能——要么因为它太小，太大，不是对齐大小，或者[会重叠到进程地址空间的末尾](https://sourceware.org/git/gitweb.cgi?p=glibc.git;a=blob;f=malloc/malloc.c;h=6e766d11bc85b6480fa5c9f2a76559f8acf9deb5;hb=HEAD#l4175)。
* 它检查块是否位于[竞技场的边界内](https://sourceware.org/git/gitweb.cgi?p=glibc.git;a=blob;f=malloc/malloc.c;h=6e766d11bc85b6480fa5c9f2a76559f8acf9deb5;hb=HEAD#l4318)。
* 它通过检查位于下一个块开头的元数据中的相应“P”位来检查块是否已经标记为自由，以确保块[尚未标记为自由](https://sourceware.org/git/gitweb.cgi?p=glibc.git;a=blob;f=malloc/malloc.c;h=6e766d11bc85b6480fa5c9f2a76559f8acf9deb5;hb=HEAD#l4182)。
## Bins

为了提高存储块的效率，每个块不仅仅存在于一个链表中，而是有几种类型。这些是bins，有5种类型的bins：[62](https://sourceware.org/git/gitweb.cgi?p=glibc.git;a=blob;f=malloc/malloc.c;h=6e766d11bc85b6480fa5c9f2a76559f8acf9deb5;hb=HEAD#l1407) small bins，63 large bins，1 unsorted bin，10 fast bins和每个线程64个tcache bins。

未排序、small和large bins的初始地址都在同一个数组中。索引0未使用，1是未排序bin，bins 2-64是small bins，bins 65-127是large bins。

### Small Bins

Small bins比large bins更快，但比fast bins慢。

62个bin中的每个bin都有**相同大小的块**：16、24、...（在32位系统中最大为504字节，在64位系统中为1024字节）。这有助于加快查找应分配空间的bin以及在这些列表中插入和删除条目的速度。

### Large Bins

与管理固定大小块的small bins不同，每个**large bin处理一系列块大小**。这更加灵活，允许系统**容纳各种大小**而无需为每个大小单独设置bin。

在内存分配器中，large bins从small bins结束的地方开始。大bin的范围逐渐变大，意味着第一个bin可能覆盖512到576字节的块，而下一个覆盖576到640字节的块。这种模式继续下去，最大的bin包含所有大于1MB的块。

与small bins相比，large bins的操作速度较慢，因为它们必须**对包含不同块大小的列表进行排序和搜索**以找到最佳匹配的分配。当将块插入large bin时，必须对其进行排序，当分配内存时，系统必须找到正确的块。这额外的工作使它们**更慢**，但由于大块分配比小块分配更少见，这是一个可以接受的折衷。

有：

- 32个64字节范围的bins
- 16个512字节范围的bins
- 8个4096字节范围的bins
- 4个32768字节范围的bins
- 2个262144字节范围的bins
- 1个用于剩余大小的bin

### Unsorted Bin

未排序bin是堆管理器用来加快内存分配的**快速缓存**。它的工作原理如下：当程序释放内存时，堆管理器不会立即将其放入特定的bin中。相反，它首先尝试**将其与任何相邻的空闲块合并**以创建更大的空闲内存块。然后，它将这个新块放入一个称为“未排序bin”的通用bin中。

当程序**请求内存**时，堆管理器**首先检查未排序bin**，看看是否有合适大小的块。如果找到一个，它会立即使用，这比搜索其他bins要快。如果找不到合适的块，它会将释放的块移动到它们正确的bins中，无论是small还是large，都基于它们的大小。

因此，未排序bin是通过快速重用最近释放的内存来加速内存分配，并减少耗时的搜索和合并的需求。

{% hint style="danger" %}
请注意，即使块属于不同的类别，有时如果一个可用块与另一个可用块发生冲突（即使它们属于不同的类别），它们将被合并。
{% endhint %}

### Fast Bins

Fast bins旨在通过将最近释放的块保留在快速访问结构中来**加速小块的内存分配**。这些bins使用后进先出（LIFO）方法，这意味着**最近释放的块是第一个**在有新的分配请求时被重用的块。这种行为对速度有利，因为与队列（FIFO）相比，从堆栈（LIFO）顶部插入和删除更快。

此外，**fast bins使用单链表**，而不是双链表，这进一步提高了速度。由于fast bins中的块不会与相邻块合并，因此不需要允许从中间删除的复杂结构。单链表对于这些操作更简单、更快。

基本上，这里发生的情况是头部（指向要检查的第一个块的指针）始终指向该大小的最新释放块。因此：

- 当分配该大小的新块时，头部指向一个可用块以供使用。由于此可用块指向下一个要使用的块，因此将此地址存储在头部中，以便下一个分配知道从哪里获取可用块
- 当释放块时，空闲块将保存当前可用块的地址，并将这个新释放块的地址放入头部

{% hint style="danger" %}
fast bins中的块不会自动设置为可用，因此它们会保持为fast bin块一段时间，而不是能够与其他块合并。
{% endhint %}

### Tcache（每线程缓存）Bins

尽管线程尝试拥有自己的堆（参见[Arenas](./#arenas)和[Subheaps](./#subheaps)），但有可能一个具有大量线程的进程（如Web服务器）**最终会与其他线程共享堆**。在这种情况下，主要解决方案是使用**锁**，这可能**显著减慢线程**。

因此，tcache类似于每个线程的fast bin，因为它是一个**不合并块的单链表**。每个线程有**64个单链tcache bins**。每个bin可以拥有[7个相同大小的块](https://sourceware.org/git/?p=glibc.git;a=blob;f=malloc/malloc.c;h=2527e2504761744df2bdb1abdc02d936ff907ad2;hb=d5c3fafc4307c9b7a4c7d5cb381fcdbfad340bcc#l323)，范围从[24到1032字节（64位系统）和12到516字节（32位系统）](https://sourceware.org/git/?p=glibc.git;a=blob;f=malloc/malloc.c;h=2527e2504761744df2bdb1abdc02d936ff907ad2;hb=d5c3fafc4307c9b7a4c7d5cb381fcdbfad340bcc#l315)。

**当线程释放**一个块时，**如果它不太大**以至于无法在tcache中分配，并且相应的tcache bin**未满**（已有7个块），**它将被分配到那里**。如果无法进入tcache，则需要等待堆锁以执行全局释放操作。

当**分配块**时，如果**Tcache中有所需大小的空闲块**，它将使用它，否则，它将需要等待堆锁以在全局bins中找到一个或创建一个新的。

还有一个优化，在这种情况下，当持有堆锁时，线程**将用请求大小的堆块（7个）填充其Tcache**，因此如果需要更多，它将在Tcache中找到它们。
### 分配顺序

#### 用于分配：

1. 如果该大小的 Tcache 中有可用块，则使用 Tcache
2. 如果太大，使用 mmap
3. 获取堆区锁并：
1. 如果有足够小的大小，可用请求大小的快速 bin 块，则使用它，并从快速 bin 预填充 tcache
2. 检查未排序列表中的每个条目，寻找足够大的一个块，并在可能的情况下从快速 bin 预填充 tcache
3. 检查小块或大块（根据请求的大小），并在可能的情况下从 tcache 预填充 tcache
4. 从可用内存创建一个新块
1. 如果没有可用内存，请使用 `sbrk` 获取更多
2. 如果主堆内存无法再增长，请使用 mmap 创建新空间
5. 如果什么都没用，请返回 null

**用于释放：**

1. 如果指针为空，则结束
2. 在块中执行 `free` 安全检查，尝试验证其是否为合法块
1. 如果足够小且 tcache 未满，请将其放入其中
2. 如果设置了位 M（非堆），请使用 `munmap`
3. 获取堆区锁：
1. 如果适合快速 bin，请将其放入其中
2. 如果块大于 64KB，请立即合并快速 bin，并将结果合并后的块放入未排序 bin 中。
3. 与相邻的已释放块在小、大和未排序 bin 中向后和向前合并块。
4. 如果在头部，将其合并到未使用内存中
5. 如果不是前面的情况，请将其存储在未排序列表中



\

快速堆示例来自 [https://guyinatuxedo.github.io/25-heap/index.html](https://guyinatuxedo.github.io/25-heap/index.html)，但在 arm64 上：
```c
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

void main(void)
{
char *ptr;
ptr = malloc(0x10);
strcpy(ptr, "panda");
}
```
在主函数的末尾设置一个断点，让我们找出信息存储在哪里：

<figure><img src="../../.gitbook/assets/image (1239).png" alt=""><figcaption></figcaption></figure>

可以看到字符串"panda"被存储在`0xaaaaaaac12a0`（这是由`x0`内的malloc返回的地址）。检查它之前的0x10个字节，可以看到`0x0`表示**前一个块未被使用**（长度为0），而这个块的长度为`0x21`。

额外保留的空间（0x21-0x10=0x11）来自于**添加的头部**（0x10），0x1并不意味着0x21B被保留，而是当前头部长度的最后3位具有一些特殊含义。由于长度始终是16字节对齐的（在64位机器上），这些位实际上永远不会被长度数字使用。
```
0x1:     Previous in Use     - Specifies that the chunk before it in memory is in use
0x2:     Is MMAPPED          - Specifies that the chunk was obtained with mmap()
0x4:     Non Main Arena      - Specifies that the chunk was obtained from outside of the main arena
```
##

## 参考资料

* [https://azeria-labs.com/heap-exploitation-part-1-understanding-the-glibc-heap-implementation/](https://azeria-labs.com/heap-exploitation-part-1-understanding-the-glibc-heap-implementation/)
* [https://azeria-labs.com/heap-exploitation-part-2-glibc-heap-free-bins/](https://azeria-labs.com/heap-exploitation-part-2-glibc-heap-free-bins/)
